# ğŸŒ åˆ†å¸ƒå¼å‹æµ‹æ¶æ„è®¾è®¡

## ğŸ“‹ ç›®å½•

- [æ¶æ„æ¦‚è¿°](#-æ¶æ„æ¦‚è¿°)
- [æ ¸å¿ƒæ¦‚å¿µ](#-æ ¸å¿ƒæ¦‚å¿µ)
- [ç³»ç»Ÿæ¶æ„](#-ç³»ç»Ÿæ¶æ„)
- [é€šä¿¡åè®®](#-é€šä¿¡åè®®)
- [æ•°æ®æµè½¬](#-æ•°æ®æµè½¬)
- [å®ç°æ–¹æ¡ˆ](#-å®ç°æ–¹æ¡ˆ)

---

## ğŸ¯ æ¶æ„æ¦‚è¿°

### è®¾è®¡ç›®æ ‡

- ğŸš€ **é«˜ååé‡**ï¼šæ”¯æŒæ•°ä¸‡ QPS çš„åˆ†å¸ƒå¼å‹æµ‹èƒ½åŠ›
- ğŸ”§ **æ˜“æ‰©å±•**ï¼šåŠ¨æ€æ·»åŠ /ç§»é™¤è‚‰é¸¡èŠ‚ç‚¹
- ğŸ“Š **å®æ—¶æ±‡æ€»**ï¼šä¸»èŠ‚ç‚¹å®æ—¶æ”¶é›†å¹¶æ±‡æ€»æ‰€æœ‰èŠ‚ç‚¹ç»Ÿè®¡æ•°æ®
- ğŸ›¡ï¸ **é«˜å¯ç”¨**ï¼šè‚‰é¸¡èŠ‚ç‚¹æ•…éšœä¸å½±å“å…¶ä»–èŠ‚ç‚¹è¿è¡Œ
- ğŸ›ï¸ **ç»Ÿä¸€è°ƒåº¦**ï¼šä¸»èŠ‚ç‚¹ç»Ÿä¸€æ§åˆ¶æ‰€æœ‰è‚‰é¸¡èŠ‚ç‚¹çš„å‹æµ‹ä»»åŠ¡

### åº”ç”¨åœºæ™¯

- è¶…å¤§è§„æ¨¡å‹æµ‹ï¼ˆå•æœºå‹æµ‹èƒ½åŠ›ä¸è¶³ï¼‰
- åˆ†å¸ƒå¼åœºæ™¯æ¨¡æ‹Ÿï¼ˆä¸åŒåœ°åŸŸã€ç½‘ç»œç¯å¢ƒï¼‰
- å¤šç›®æ ‡å¹¶å‘å‹æµ‹
- é•¿æ—¶é—´ç¨³å®šæ€§æµ‹è¯•

---

## ğŸ—ï¸ æ ¸å¿ƒæ¦‚å¿µ

### è§’è‰²å®šä¹‰

```mermaid
graph TB
    subgraph "Master Node (ä¸»èŠ‚ç‚¹)"
        M[Master Controller]
        MA[Slave Manager]
        MC[Result Collector]
        MR[Report Generator]
    end
    
    subgraph "Slave Node 1 (è‚‰é¸¡1)"
        A1[Slave Controller]
        A1E[Local Executor]
        A1S[Statistics Sender]
    end
    
    subgraph "Slave Node 2 (è‚‰é¸¡2)"
        A2[Slave Controller]
        A2E[Local Executor]
        A2S[Statistics Sender]
    end
    
    subgraph "Slave Node N (è‚‰é¸¡N)"
        AN[Slave Controller]
        ANE[Local Executor]
        ANS[Statistics Sender]
    end
    
    M --> MA
    MA -->|åˆ†å‘ä»»åŠ¡| A1
    MA -->|åˆ†å‘ä»»åŠ¡| A2
    MA -->|åˆ†å‘ä»»åŠ¡| AN
    
    A1S -->|ä¸ŠæŠ¥ç»Ÿè®¡| MC
    A2S -->|ä¸ŠæŠ¥ç»Ÿè®¡| MC
    ANS -->|ä¸ŠæŠ¥ç»Ÿè®¡| MC
    
    MC --> MR
    
    style M fill:#e1f5ff
    style A1 fill:#ffe1e1
    style A2 fill:#ffe1e1
    style AN fill:#ffe1e1
```

| è§’è‰² | èŒè´£ | éƒ¨ç½²ä½ç½® |
|:-----|:-----|:---------|
| **Master (ä¸»èŠ‚ç‚¹)** | ä»»åŠ¡è°ƒåº¦ã€é…ç½®åˆ†å‘ã€ç»“æœæ±‡æ€»ã€æŠ¥å‘Šç”Ÿæˆ | ä¸­å¿ƒæœåŠ¡å™¨ |
| **Slave (è‚‰é¸¡èŠ‚ç‚¹)** | æ¥æ”¶ä»»åŠ¡ã€æ‰§è¡Œå‹æµ‹ã€ä¸ŠæŠ¥ç»Ÿè®¡ | åˆ†å¸ƒå¼æœåŠ¡å™¨ |

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„

```mermaid
graph TB
    subgraph "Master Layer (ä¸»èŠ‚ç‚¹å±‚)"
        CLI[CLI/WebUI]
        Master[Master Controller]
        TaskQueue[Task Queue]
        AgentPool[Slave Pool]
        Collector[Result Collector]
        Aggregator[Data Aggregator]
        Reporter[Report Generator]
    end
    
    subgraph "Communication Layer (é€šä¿¡å±‚)"
        MsgBroker[Message Broker<br/>gRPC/HTTP]
        HealthCheck[Health Check]
    end
    
    subgraph "Slave Layer 1 (è‚‰é¸¡å±‚1)"
        Agent1[Slave Controller]
        Exec1[Local Executor]
        Stats1[Statistics Buffer]
    end
    
    subgraph "Slave Layer 2 (è‚‰é¸¡å±‚2)"
        Agent2[Slave Controller]
        Exec2[Local Executor]
        Stats2[Statistics Buffer]
    end
    
    subgraph "Slave Layer N (è‚‰é¸¡å±‚N)"
        AgentN[Slave Controller]
        ExecN[Local Executor]
        StatsN[Statistics Buffer]
    end
    
    subgraph "Target Services (ç›®æ ‡æœåŠ¡)"
        Target[HTTP/gRPC Services]
    end
    
    CLI --> Master
    Master --> TaskQueue
    Master --> AgentPool
    TaskQueue --> MsgBroker
    MsgBroker --> Agent1
    MsgBroker --> Agent2
    MsgBroker --> AgentN
    
    Agent1 --> Exec1
    Agent2 --> Exec2
    AgentN --> ExecN
    
    Exec1 --> Target
    Exec2 --> Target
    ExecN --> Target
    
    Stats1 --> Collector
    Stats2 --> Collector
    StatsN --> Collector
    
    Collector --> Aggregator
    Aggregator --> Reporter
    
    HealthCheck -.ç›‘æ§.-> Agent1
    HealthCheck -.ç›‘æ§.-> Agent2
    HealthCheck -.ç›‘æ§.-> AgentN
    
    style Master fill:#e1f5ff
    style Agent1 fill:#ffe1e1
    style Agent2 fill:#ffe1e1
    style AgentN fill:#ffe1e1
    style Collector fill:#e1ffe1
```

### ç»„ä»¶è¯¦è§£

#### Master èŠ‚ç‚¹ç»„ä»¶

| ç»„ä»¶ | èŒè´£ | æ ¸å¿ƒåŠŸèƒ½ |
|:-----|:-----|:---------|
| **Master Controller** | æ€»æ§åˆ¶å™¨ | ä»»åŠ¡ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€Agent æ³¨å†Œç®¡ç† |
| **Slave Pool** | Slave æ±  | ç»´æŠ¤å¯ç”¨ Slave åˆ—è¡¨ã€å¥åº·æ£€æŸ¥ |
| **Task Queue** | ä»»åŠ¡é˜Ÿåˆ— | ä»»åŠ¡åˆ†ç‰‡ã€åˆ†å‘ç­–ç•¥ã€å¤±è´¥é‡è¯• |
| **Result Collector** | ç»“æœæ”¶é›†å™¨ | æ¥æ”¶ Slave ä¸ŠæŠ¥æ•°æ®ã€æ•°æ®ç¼“å­˜ |
| **Data Aggregator** | æ•°æ®èšåˆå™¨ | å®æ—¶æ±‡æ€»ã€ç»Ÿè®¡è®¡ç®—ã€æ—¶é—´çª—å£èšåˆ |
| **Report Generator** | æŠ¥å‘Šç”Ÿæˆå™¨ | ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šã€å¯è§†åŒ–å›¾è¡¨ |

#### Slave èŠ‚ç‚¹ç»„ä»¶

| ç»„ä»¶ | èŒè´£ | æ ¸å¿ƒåŠŸèƒ½ |
|:-----|:-----|:---------|
| **Slave Controller** | Slave æ§åˆ¶å™¨ | æ¥æ”¶ Master æŒ‡ä»¤ã€å¯åŠ¨/åœæ­¢å‹æµ‹ |
| **Local Executor** | æœ¬åœ°æ‰§è¡Œå™¨ | æ‰§è¡Œå‹æµ‹ä»»åŠ¡ï¼ˆå¤ç”¨ç°æœ‰ Executorï¼‰ |
| **Statistics Buffer** | ç»Ÿè®¡ç¼“å†²åŒº | ç¼“å­˜ç»Ÿè®¡æ•°æ®ã€æ‰¹é‡ä¸ŠæŠ¥ |
| **Health Reporter** | å¥åº·ä¸ŠæŠ¥å™¨ | ä¸ŠæŠ¥èŠ‚ç‚¹çŠ¶æ€ã€èµ„æºä½¿ç”¨æƒ…å†µ |

---

## ğŸ“¡ é€šä¿¡åè®®

### åè®®é€‰å‹

| åè®® | åœºæ™¯ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|:-----|:-----|:-----|:-----|
| **gRPC** | æ§åˆ¶æŒ‡ä»¤ã€å®æ—¶æ•°æ® | é«˜æ€§èƒ½ã€åŒå‘æµã€å¼ºç±»å‹ | å®ç°å¤æ‚ |
| **HTTP/REST** | é…ç½®ä¸‹å‘ã€æŠ¥å‘ŠæŸ¥è¯¢ | ç®€å•æ˜“ç”¨ã€å¹¿æ³›æ”¯æŒ | æ€§èƒ½è¾ƒä½ |
| **WebSocket** | å®æ—¶ç›‘æ§ã€æ—¥å¿—æµ | å®æ—¶åŒå‘ã€æŒä¹…è¿æ¥ | çŠ¶æ€ç»´æŠ¤ |

**æ¨èæ–¹æ¡ˆ**ï¼šgRPCï¼ˆä¸»é€šä¿¡ï¼‰ + HTTPï¼ˆè¾…åŠ©ç®¡ç†ï¼‰

### gRPC æ¥å£å®šä¹‰

```protobuf
syntax = "proto3";

package stress;

// Master æœåŠ¡æ¥å£
service MasterService {
  // Slave æ³¨å†Œ
  rpc RegisterAgent(AgentInfo) returns (RegisterResponse);
  
  // Slave å¿ƒè·³
  rpc Heartbeat(HeartbeatRequest) returns (HeartbeatResponse);
  
  // ä¸ŠæŠ¥ç»Ÿè®¡æ•°æ®ï¼ˆæµå¼ï¼‰
  rpc ReportStats(stream StatsData) returns (ReportResponse);
}

// Slave æœåŠ¡æ¥å£
service AgentService {
  // æ¥æ”¶ä»»åŠ¡
  rpc ExecuteTask(TaskConfig) returns (TaskResponse);
  
  // åœæ­¢ä»»åŠ¡
  rpc StopTask(StopRequest) returns (StopResponse);
  
  // æŸ¥è¯¢çŠ¶æ€
  rpc GetStatus(StatusRequest) returns (AgentStatus);
}

// Slave ä¿¡æ¯
message AgentInfo {
  string agent_id = 1;
  string hostname = 2;
  string ip = 3;
  int32 cpu_cores = 4;
  int64 memory = 5;
  string version = 6;
}

// ä»»åŠ¡é…ç½®
message TaskConfig {
  string task_id = 1;
  string protocol = 2;      // http/grpc
  string target = 3;
  int32 worker_count = 4;
  int32 duration = 5;
  int32 ramp_up = 6;
  bytes config_data = 7;    // JSON åºåˆ—åŒ–çš„è¯¦ç»†é…ç½®
}

// ç»Ÿè®¡æ•°æ®
message StatsData {
  string agent_id = 1;
  int64 timestamp = 2;
  int64 total_requests = 3;
  int64 success_count = 4;
  int64 failed_count = 5;
  double avg_latency = 6;
  double p95_latency = 7;
  double p99_latency = 8;
  double qps = 9;
  map<string, int64> status_codes = 10;
}

// Slave çŠ¶æ€
message AgentStatus {
  string agent_id = 1;
  string state = 2;         // idle/running/error
  string current_task_id = 3;
  double cpu_usage = 4;
  double memory_usage = 5;
  int64 running_workers = 6;
}
```

### æ¶ˆæ¯ç±»å‹

```mermaid
sequenceDiagram
    participant Master
    participant Slave
    participant Executor
    
    Note over Master,Slave: 1. æ³¨å†Œé˜¶æ®µ
    Slave->>Master: RegisterAgent(AgentInfo)
    Master-->>Slave: RegisterResponse(agent_id, token)
    
    Note over Master,Slave: 2. ä»»åŠ¡åˆ†å‘
    Master->>Slave: ExecuteTask(TaskConfig)
    Slave->>Executor: Initialize & Start
    Slave-->>Master: TaskResponse(accepted)
    
    Note over Master,Slave: 3. å¿ƒè·³ç›‘æ§
    loop æ¯5ç§’
        Slave->>Master: Heartbeat(status)
        Master-->>Slave: HeartbeatResponse(ok)
    end
    
    Note over Master,Slave: 4. æ•°æ®ä¸ŠæŠ¥
    loop æ¯1ç§’
        Executor->>Slave: Collect Stats
        Slave->>Master: ReportStats(StatsData)
    end
    
    Note over Master,Slave: 5. ä»»åŠ¡åœæ­¢
    Master->>Slave: StopTask(task_id)
    Slave->>Executor: Shutdown
    Slave-->>Master: StopResponse(stopped)
```

---

## ğŸ”„ æ•°æ®æµè½¬

### ä»»åŠ¡æ‰§è¡Œæµç¨‹

```mermaid
stateDiagram-v2
    [*] --> AgentRegister: Agentå¯åŠ¨
    AgentRegister --> Idle: æ³¨å†ŒæˆåŠŸ
    Idle --> TaskReceived: æ¥æ”¶ä»»åŠ¡
    TaskReceived --> Preparing: å‡†å¤‡èµ„æº
    Preparing --> Running: å¼€å§‹æ‰§è¡Œ
    Running --> Running: æŒç»­å‹æµ‹+ä¸ŠæŠ¥
    Running --> Stopping: æ”¶åˆ°åœæ­¢ä¿¡å·
    Running --> Error: æ‰§è¡Œé”™è¯¯
    Stopping --> Idle: æ¸…ç†èµ„æº
    Error --> Idle: é”™è¯¯æ¢å¤
    Idle --> [*]: Agentä¸‹çº¿
```

### ç»Ÿè®¡æ•°æ®èšåˆ

```go
// ç»Ÿè®¡æ•°æ®èšåˆç­–ç•¥
type AggregationStrategy struct {
    WindowSize   time.Duration  // èšåˆçª—å£ï¼ˆå¦‚ 1s, 5sï¼‰
    BufferSize   int            // ç¼“å†²åŒºå¤§å°
    FlushPolicy  FlushPolicy    // åˆ·æ–°ç­–ç•¥ï¼ˆæ—¶é—´/å¤§å°ï¼‰
}

// èšåˆç»´åº¦
type AggregationDimension struct {
    ByAgent      bool  // æŒ‰ Slave èšåˆ
    ByAPI        bool  // æŒ‰ API èšåˆ
    ByStatusCode bool  // æŒ‰çŠ¶æ€ç èšåˆ
    ByTimeWindow bool  // æŒ‰æ—¶é—´çª—å£èšåˆ
}

// èšåˆç»“æœ
type AggregatedStats struct {
    TimeRange    TimeRange              // æ—¶é—´èŒƒå›´
    TotalAgents  int                    // å‚ä¸ Slave æ•°
    TotalReqs    int64                  // æ€»è¯·æ±‚æ•°
    TotalSuccess int64                  // æ€»æˆåŠŸæ•°
    TotalFailed  int64                  // æ€»å¤±è´¥æ•°
    AvgLatency   float64                // å¹³å‡å»¶è¿Ÿ
    P95Latency   float64                // P95 å»¶è¿Ÿ
    P99Latency   float64                // P99 å»¶è¿Ÿ
    TotalQPS     float64                // æ€» QPS
    ByAgent      map[string]*AgentStats // å„ Slave ç»Ÿè®¡
    ByAPI        map[string]*APIStats   // å„ API ç»Ÿè®¡
    StatusCodes  map[int]int64          // çŠ¶æ€ç åˆ†å¸ƒ
}
```

---

## ğŸ’» å®ç°æ–¹æ¡ˆ

### æ ¸å¿ƒæ•°æ®ç»“æ„

```go
// Master èŠ‚ç‚¹
type Master struct {
    agentPool    *AgentPool
    taskQueue    *TaskQueue
    collector    *ResultCollector
    aggregator   *DataAggregator
    grpcServer   *grpc.Server
    httpServer   *http.Server
}

// Slave èŠ‚ç‚¹
type Slave struct {
    id           string
    masterAddr   string
    executor     *executor.Executor
    statsBuffer  *StatsBuffer
    grpcClient   MasterServiceClient
    grpcServer   *grpc.Server
    status       AgentStatus
}

// Slave æ± 
type AgentPool struct {
    mu           sync.RWMutex
    agents       map[string]*AgentInfo
    healthCheck  *HealthChecker
    selector     AgentSelector  // è´Ÿè½½å‡è¡¡ç­–ç•¥
}

// ä»»åŠ¡é˜Ÿåˆ—
type TaskQueue struct {
    mu           sync.Mutex
    pending      []*Task
    running      map[string]*Task
    splitter     TaskSplitter  // ä»»åŠ¡åˆ†ç‰‡ç­–ç•¥
}

// ç»“æœæ”¶é›†å™¨
type ResultCollector struct {
    mu           sync.RWMutex
    buffer       chan *StatsData
    cache        *StatsCache
    persistor    StatsPersistor
}

// æ•°æ®èšåˆå™¨
type DataAggregator struct {
    mu           sync.RWMutex
    strategy     AggregationStrategy
    windows      map[string]*TimeWindow
    calculator   StatsCalculator
}
```

### ä»»åŠ¡åˆ†ç‰‡ç­–ç•¥

```go
// ä»»åŠ¡åˆ†ç‰‡å™¨
type TaskSplitter interface {
    Split(task *Task, agentCount int) []*SubTask
}

// å¹³å‡åˆ†ç‰‡ï¼ˆé»˜è®¤ï¼‰
type EqualSplitter struct{}

func (s *EqualSplitter) Split(task *Task, agentCount int) []*SubTask {
    workersPerAgent := task.WorkerCount / agentCount
    remainder := task.WorkerCount % agentCount
    
    subTasks := make([]*SubTask, agentCount)
    for i := 0; i < agentCount; i++ {
        subTasks[i] = &SubTask{
            TaskID:      fmt.Sprintf("%s-part-%d", task.ID, i),
            WorkerCount: workersPerAgent,
            Config:      task.Config,
        }
        // å°†ä½™æ•°åˆ†é…ç»™å‰é¢çš„ Slave
        if i < remainder {
            subTasks[i].WorkerCount++
        }
    }
    return subTasks
}

// æƒé‡åˆ†ç‰‡ï¼ˆæ ¹æ® Slave èƒ½åŠ›ï¼‰
type WeightedSplitter struct {
    weights map[string]float64  // agent_id -> weight
}

func (s *WeightedSplitter) Split(task *Task, agents []*AgentInfo) []*SubTask {
    totalWeight := 0.0
    for _, slave := range agents {
        totalWeight += s.getWeight(slave)
    }
    
    subTasks := make([]*SubTask, len(agents))
    for i, slave := range agents {
        weight := s.getWeight(slave)
        workerCount := int(float64(task.WorkerCount) * weight / totalWeight)
        subTasks[i] = &SubTask{
            TaskID:      fmt.Sprintf("%s-%s", task.ID, slave.ID),
            SlaveID:     slave.ID,
            WorkerCount: workerCount,
            Config:      task.Config,
        }
    }
    return subTasks
}

func (s *WeightedSplitter) getWeight(slave *AgentInfo) float64 {
    if w, ok := s.weights[slave.ID]; ok {
        return w
    }
    // é»˜è®¤æŒ‰ CPU æ ¸å¿ƒæ•°
    return float64(slave.CPUCores)
}
```

### Slave é€‰æ‹©ç­–ç•¥

```go
// Slave é€‰æ‹©å™¨
type AgentSelector interface {
    Select(agents []*AgentInfo, count int) []*AgentInfo
}

// éšæœºé€‰æ‹©
type RandomSelector struct{}

func (s *RandomSelector) Select(agents []*AgentInfo, count int) []*AgentInfo {
    if count >= len(agents) {
        return agents
    }
    
    rand.Shuffle(len(agents), func(i, j int) {
        agents[i], agents[j] = agents[j], agents[i]
    })
    return agents[:count]
}

// è´Ÿè½½æœ€ä½é€‰æ‹©
type LeastLoadedSelector struct{}

func (s *LeastLoadedSelector) Select(agents []*AgentInfo, count int) []*AgentInfo {
    sort.Slice(agents, func(i, j int) bool {
        return agents[i].CurrentLoad < agents[j].CurrentLoad
    })
    
    if count >= len(agents) {
        return agents
    }
    return agents[:count]
}

// åœ°åŸŸæ„ŸçŸ¥é€‰æ‹©
type LocationAwareSelector struct {
    preferredRegions []string
}

func (s *LocationAwareSelector) Select(agents []*AgentInfo, count int) []*AgentInfo {
    preferred := make([]*AgentInfo, 0)
    others := make([]*AgentInfo, 0)
    
    for _, slave := range agents {
        if s.isPreferred(slave.Region) {
            preferred = append(preferred, slave)
        } else {
            others = append(others, slave)
        }
    }
    
    result := make([]*AgentInfo, 0, count)
    result = append(result, preferred...)
    if len(result) < count {
        result = append(result, others[:count-len(result)]...)
    }
    return result[:count]
}
```

### å¥åº·æ£€æŸ¥æœºåˆ¶

```go
// å¥åº·æ£€æŸ¥å™¨
type HealthChecker struct {
    pool         *AgentPool
    interval     time.Duration
    timeout      time.Duration
    maxFailures  int
    failureCount map[string]int
}

func (hc *HealthChecker) Start(ctx context.Context) {
    ticker := time.NewTicker(hc.interval)
    defer ticker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            hc.checkAll()
        }
    }
}

func (hc *HealthChecker) checkAll() {
    agents := hc.pool.GetAllAgents()
    
    for _, slave := range agents {
        go func(a *AgentInfo) {
            if err := hc.checkAgent(a); err != nil {
                hc.handleFailure(a)
            } else {
                hc.handleSuccess(a)
            }
        }(slave)
    }
}

func (hc *HealthChecker) checkAgent(slave *AgentInfo) error {
    ctx, cancel := context.WithTimeout(context.Background(), hc.timeout)
    defer cancel()
    
    client := hc.getGRPCClient(slave)
    _, err := client.Heartbeat(ctx, &HeartbeatRequest{
        SlaveID:   slave.ID,
        Timestamp: time.Now().Unix(),
    })
    return err
}

func (hc *HealthChecker) handleFailure(slave *AgentInfo) {
    hc.failureCount[slave.ID]++
    
    if hc.failureCount[slave.ID] >= hc.maxFailures {
        // æ ‡è®° Slave ä¸ºä¸å¯ç”¨
        hc.pool.MarkUnhealthy(slave.ID)
        logger.Warn("Slave marked as unhealthy",
            "agent_id", slave.ID,
            "failures", hc.failureCount[slave.ID])
    }
}

func (hc *HealthChecker) handleSuccess(slave *AgentInfo) {
    // é‡ç½®å¤±è´¥è®¡æ•°
    hc.failureCount[slave.ID] = 0
    hc.pool.MarkHealthy(slave.ID)
}
```

### ç»Ÿè®¡æ•°æ®ä¸ŠæŠ¥

```go
// ç»Ÿè®¡ç¼“å†²åŒº
type StatsBuffer struct {
    mu           sync.Mutex
    slaveID      string
    buffer       []*statistics.Record
    maxSize      int
    flushTicker  *time.Ticker
    client       MasterServiceClient
}

func (sb *StatsBuffer) Add(record *statistics.Record) {
    sb.mu.Lock()
    defer sb.mu.Unlock()
    
    sb.buffer = append(sb.buffer, record)
    
    // ç¼“å†²åŒºæ»¡æ—¶ç«‹å³åˆ·æ–°
    if len(sb.buffer) >= sb.maxSize {
        go sb.Flush()
    }
}

func (sb *StatsBuffer) Start(ctx context.Context) {
    sb.flushTicker = time.NewTicker(1 * time.Second)
    defer sb.flushTicker.Stop()
    
    for {
        select {
        case <-ctx.Done():
            sb.Flush() // æœ€ååˆ·æ–°ä¸€æ¬¡
            return
        case <-sb.flushTicker.C:
            sb.Flush()
        }
    }
}

func (sb *StatsBuffer) Flush() error {
    sb.mu.Lock()
    if len(sb.buffer) == 0 {
        sb.mu.Unlock()
        return nil
    }
    
    // å¤åˆ¶å¹¶æ¸…ç©ºç¼“å†²åŒº
    toSend := make([]*statistics.Record, len(sb.buffer))
    copy(toSend, sb.buffer)
    sb.buffer = sb.buffer[:0]
    sb.mu.Unlock()
    
    // èšåˆæ•°æ®
    statsData := sb.aggregate(toSend)
    
    // å‘é€åˆ° Master
    ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
    defer cancel()
    
    stream, err := sb.client.ReportStats(ctx)
    if err != nil {
        return err
    }
    
    return stream.Send(statsData)
}

func (sb *StatsBuffer) aggregate(records []*statistics.Record) *StatsData {
    data := &StatsData{
        SlaveID:   sb.slaveID,
        Timestamp: time.Now().Unix(),
    }
    
    latencies := make([]float64, 0, len(records))
    statusCodes := make(map[string]int64)
    
    for _, r := range records {
        data.TotalRequests++
        if r.Success {
            data.SuccessCount++
        } else {
            data.FailedCount++
        }
        latencies = append(latencies, r.Latency)
        statusCodes[fmt.Sprintf("%d", r.StatusCode)]++
    }
    
    // è®¡ç®—å»¶è¿Ÿç™¾åˆ†ä½
    sort.Float64s(latencies)
    if len(latencies) > 0 {
        data.AvgLatency = mathx.Average(latencies)
        data.P95Latency = mathx.Percentile(latencies, 95)
        data.P99Latency = mathx.Percentile(latencies, 99)
    }
    
    data.StatusCodes = statusCodes
    data.Qps = float64(data.TotalRequests) / 1.0 // 1ç§’çª—å£
    
    return data
}
```

---

## ğŸ¯ ä½¿ç”¨ç¤ºä¾‹

### Master å¯åŠ¨

```bash
# å¯åŠ¨ Master èŠ‚ç‚¹
go-stress master start \
  --grpc-port 50051 \
  --http-port 8080 \
  --log-level info
```

### Slave å¯åŠ¨

```bash
# åœ¨å„ä¸ªè‚‰é¸¡æœºå™¨ä¸Šå¯åŠ¨ Slave
go-stress slave start \
  --master-addr 192.168.1.100:50051 \
  --slave-id slave-001 \
  --grpc-port 50052
```

### æäº¤åˆ†å¸ƒå¼ä»»åŠ¡

```bash
# æäº¤åˆ†å¸ƒå¼å‹æµ‹ä»»åŠ¡
go-stress run distributed \
  --config test.yaml \
  --agents 10 \          # ä½¿ç”¨ 10 ä¸ª Slave
  --duration 60s \
  --workers-per-slave 100
```

### é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# distributed-test.yaml
distributed:
  master_addr: "192.168.1.100:50051"
  agent_count: 5
  agent_selector: "least_loaded"  # random/least_loaded/location_aware
  task_splitter: "weighted"       # equal/weighted
  
stress:
  protocol: http
  target: "https://api.example.com"
  duration: 300s
  ramp_up: 60s
  
  # æ¯ä¸ª Slave çš„é…ç½®
  per_agent:
    worker_count: 100
    connection_pool: 50
  
  # ç»Ÿè®¡ä¸ŠæŠ¥é…ç½®
  stats:
    report_interval: 1s
    buffer_size: 1000
    aggregation_window: 5s
```

---

## ğŸ“Š ç›‘æ§ä¸å¯è§†åŒ–

### å®æ—¶ç›‘æ§é¢æ¿

```
â”Œâ”€ Distributed Stress Test Dashboard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                      â”‚
â”‚  Master: 192.168.1.100:50051                    Status: â— Running   â”‚
â”‚  Task ID: dist-test-20260123                    Duration: 02:45/300sâ”‚
â”‚                                                                      â”‚
â”œâ”€ Slave Status â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Total: 5   Online: 5   Running: 5   Idle: 0   Error: 0            â”‚
â”‚                                                                      â”‚
â”‚  Slave ID      IP              Workers  QPS     Latency  Status     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  slave-001     192.168.1.101   100     1,250    45ms    â— Running  â”‚
â”‚  slave-002     192.168.1.102   100     1,180    48ms    â— Running  â”‚
â”‚  slave-003     192.168.1.103   150     1,890    42ms    â— Running  â”‚
â”‚  slave-004     192.168.1.104   100     1,220    50ms    â— Running  â”‚
â”‚  slave-005     192.168.1.105   100     1,210    46ms    â— Running  â”‚
â”‚                                                                      â”‚
â”œâ”€ Aggregated Statistics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Total Requests: 982,450              Success Rate: 99.8%           â”‚
â”‚  Total QPS: 6,750                     Failed: 1,965                 â”‚
â”‚  Avg Latency: 46.2ms                  P95: 85ms    P99: 120ms      â”‚
â”‚                                                                      â”‚
â”‚  Status Codes:  200: 98.5%   201: 0.8%   400: 0.3%   500: 0.4%     â”‚
â”‚                                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”’ å®‰å…¨æœºåˆ¶

### è®¤è¯æˆæƒ

```go
// Token è®¤è¯
type TokenAuth struct {
    secret string
    tokens map[string]*TokenInfo
}

func (ta *TokenAuth) GenerateToken(slaveID string) (string, error) {
    token := jwt.NewWithClaims(jwt.SigningMethodHS256, jwt.MapClaims{
        "agent_id": slaveID,
        "exp":      time.Now().Add(24 * time.Hour).Unix(),
    })
    return token.SignedString([]byte(ta.secret))
}

func (ta *TokenAuth) ValidateToken(tokenString string) (*TokenInfo, error) {
    token, err := jwt.Parse(tokenString, func(token *jwt.Token) (interface{}, error) {
        return []byte(ta.secret), nil
    })
    
    if err != nil || !token.Valid {
        return nil, errors.New("invalid token")
    }
    
    claims := token.Claims.(jwt.MapClaims)
    return &TokenInfo{
        SlaveID: claims["agent_id"].(string),
    }, nil
}
```

### TLS åŠ å¯†

```go
// TLS é…ç½®
func NewTLSConfig() (*tls.Config, error) {
    cert, err := tls.LoadX509KeyPair("server.crt", "server.key")
    if err != nil {
        return nil, err
    }
    
    return &tls.Config{
        Certificates: []tls.Certificate{cert},
        MinVersion:   tls.VersionTLS12,
    }, nil
}
```

---

## ğŸš€ æ‰©å±•æ€§

### åŠ¨æ€æ‰©å®¹

- æ”¯æŒè¿è¡Œæ—¶æ·»åŠ  Slave
- ä»»åŠ¡è‡ªåŠ¨é‡æ–°åˆ†ç‰‡
- å¹³æ»‘è¿ç§»æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡

### æ•…éšœæ¢å¤

- Slave æ•…éšœè‡ªåŠ¨æ£€æµ‹
- ä»»åŠ¡è‡ªåŠ¨é‡æ–°åˆ†é…
- ç»Ÿè®¡æ•°æ®è¡¥å¿æœºåˆ¶

### æ€§èƒ½ä¼˜åŒ–

- æ‰¹é‡æ•°æ®ä¸ŠæŠ¥
- è¿æ¥æ± å¤ç”¨
- å¼‚æ­¥éé˜»å¡ I/O
- æ•°æ®å‹ç¼©ä¼ è¾“

---

## ğŸ“ æ€»ç»“

åˆ†å¸ƒå¼å‹æµ‹æ¶æ„é€šè¿‡ Master-Slave æ¨¡å¼ï¼Œå®ç°äº†ï¼š

1. âœ… **æ°´å¹³æ‰©å±•**ï¼šé€šè¿‡å¢åŠ è‚‰é¸¡èŠ‚ç‚¹æå‡å‹æµ‹èƒ½åŠ›
2. âœ… **ç»Ÿä¸€è°ƒåº¦**ï¼šMaster ç»Ÿä¸€æ§åˆ¶å’Œç›‘æ§æ‰€æœ‰èŠ‚ç‚¹
3. âœ… **å®æ—¶æ±‡æ€»**ï¼šç§’çº§æ•°æ®èšåˆå’Œå±•ç¤º
4. âœ… **é«˜å¯ç”¨**ï¼šèŠ‚ç‚¹æ•…éšœè‡ªåŠ¨æ¢å¤å’Œä»»åŠ¡è¿ç§»
5. âœ… **æ˜“äºè¿ç»´**ï¼šç®€å•çš„éƒ¨ç½²å’Œé…ç½®æ–¹å¼

è¯¥æ¶æ„å¯æ”¯æŒ **æ•°ä¸‡ QPS** çš„åˆ†å¸ƒå¼å‹æµ‹èƒ½åŠ›,æ»¡è¶³å¤§è§„æ¨¡æ€§èƒ½æµ‹è¯•éœ€æ±‚ã€‚
